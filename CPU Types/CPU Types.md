## Minor CPU
The **minor CPU** utilizes **in-order processor** with **fixed pipeline** and **configurable data structures** for strict sequential execution. Enables micro-architectural correlation with real processors and pipeline visualization via MinorTrace/minorview.py.

Design Philosophy:

* Multithreading: Unsupported; placeholders for future support.
Data Structures: Fixed-size at construction; BubbleIF for queues; value-passed inter-stage data; limited dynamic allocation (MinorDynInst, ForwardLineData, FetchRequests, LSQRequests).
* Model Structure: MinorCPU (cpu.hh interfaces) → Pipeline (tick/idling) → Fetch1 (I-cache fetch), Fetch2 (line decomposition), Decode (micro-op), Execute (execution/LSQ).

**Key Data Structures:**

* InstId: Tracks identity (T/S.P/L/F.E fields for sequencing).
* MinorDynInst: Instructions as bubbles/faults/decoded insts; ref-counted.
* ForwardLineData/InstData: Pass lines/insts with bubble/fault support.
* Fetch1::FetchRequest/LSQ::LSQRequest: Handle cache requests.

**Pipeline:** Stages connected by MinorBuffer FIFOs; reverse evaluation for stalling; activity-based idling.

**Stages:**

* Fetch1: Fetches lines, manages queues, reserves Fetch2 space.
* Fetch2: Decomposes lines, predicts branches, discards mismatches.
* Decode: Micro-op decomposition, packs outputs.
* Execute: Issues/commits via FU pipelines (SelfStallingPipelines), scoreboard for deps, LSQ for memory.
* Features: Functional units with delays; LSQ for requests/transfers/store buffer; draining; debugging flags (e.g., MinorTrace for minorview.py visualization). Emphasizes timing accuracy and in-order simulation.

## O3 CPU

The **O3CPU** is gem5's **detailed out-of-order processor model** designed for **high timing accuracy**. It features an **execute-in-execute** approach to simulate instructions during the pipeline's execute stage, **avoiding errors from early execution** and **preserving out-of-order load interactions**. The model uses template policies for polymorphism without virtual functions, enabling compile-time CPU definition, and separates ISA-dependent code for easier future ISA implementations. Interactions with ThreadContext allow reads but require pipeline flushes for writes to maintain architectural state integrity.

**Pipeline Stages**
* Fetch: Retrieves instructions, creates DynInst objects, selects threads, and manages branch prediction.
* Decode: Decodes instructions and resolves PC-relative unconditional branches early.
* Rename: Renames registers using a physical register file; stalls for resource shortages or serializing instructions.
* Issue/Execute/Writeback (IEW): Dispatches to instruction queue, issues to functional units, executes, and writes back results.
* Commit: Commits instructions, handles faults, and redirects on branch mispredictions.

Backend Pipeline Details
* Compute Instructions: Follow a chain from rename (register renaming, resource checks) to dispatch (insertion into IQ/LSQ), schedule (ready list management, FU assignment), execute (invocation of execute() function), writeback (waking dependents), and commit (ROB release).
* Load Instructions: Execute similarly to computes until LSQUnit::executeLoad(), which initiates access, handles aliasing/forwarding, sends cache requests, and completes via writeback and commit, waking dependents.
* Store Instructions: Execute like loads but defer cache writes until commit; LSQUnit::commitStores() and writebackStores() send packets post-commit, with completion releasing SQ entries.
* Misspeculations: Branch mispredictions trigger squashing in IEW; memory order violations (detected via MemDepUnit and LSQ checks) block/reschedule loads or squash on aliasing issues.

This model emphasizes timing precision, resource management, and accurate simulation of out-of-order execution.

## Simple CPU
The **SimpleCPU** is a functional, **in-order processor model** for scenarios **not requiring detailed simulation**, such as warm-ups, client systems, or basic testing. It **supports** the **new memory system** and consists of three classes.

**BaseSimpleCPU:** Base class holding architected state and common stats. Defines functions for interrupts, fetch requests, pre/post-execute actions, PC advancement, and implements ExecContext. Cannot run standalone; must inherit from AtomicSimpleCPU or TimingSimpleCPU.

**AtomicSimpleCPU:** Uses **atomic memory accesses** for latency estimates. Derives from BaseSimpleCPU; implements memory read/write, tick cycle, and defines ports to connect to cache/memory.

**TimingSimpleCPU:** Uses **timing memory accesses**, stalling on cache responses. Derives from BaseSimpleCPU; implements similar functions, ports, and response handling for memory accesses.

## Trace CPU
The **TraceCPU** replays elastic traces generated by the O3 CPU's Elastic Trace Probe, **enabling fast and accurate memory-system** (cache, interconnects, DRAM) performance exploration for **single-threaded benchmarks** in SE/FS modes. Traces capture dependencies and timing, correlated for SPEC 2006 and HPC apps, and are portable to other simulators.

**Elastic Trace Generation:**

* Uses Elastic Trace Probe on O3 CPU to monitor instructions, creating dependency graphs (RAW, order deps) and outputting two protobuf-encoded files: instruction fetch trace and elastic data memory trace.
* Trace Formats: Data trace includes seq_num, type (LOAD/STORE/COMP), p_addr, size, flags, rob_dep, comp_delay, reg_dep, weight, pc, v_addr, asid. Fetch trace includes tick, cmd, addr, size, flags, pkt_id, pc.
* Scripts/Options: SE mode via etrace_se.py with --inst-trace-file and --data-trace-file. FS mode: Checkpoint with O3 CPU, resume with tracing enabled. Requires protobuf installation.

**Replay with Trace CPU:**

* TraceCPU inherits from Base CPU, interfaces with L1 caches, and consumes traces for replay.
* Scripts/Options: Use etrace_replay.py with --data-trace-file, --inst-trace-file, --caches, --mem-size, etc., for SE/FS replay. Fields match generation traces for dependency/timing simulation.